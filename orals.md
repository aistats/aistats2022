---
title: Oral Sessions
layout: default
hide: true
---


<style>
details {
margin: 5pt;
}

details > summary {
  border: none;
  cursor: pointer;
  font-weight: bold;
}


details > ul {
}

details[open] > summary {
  background-color:  #fff;
}

</style>

<h1>{{ site.conference.short_name }} {{ site.conference.year }} Oral Session Schedule</h1>

(click on session titles to show the list of papers) 

## Day 1: Mon, March 28 

<table>
<tr>   
<th> Session Title </th>
<th> Time  (UTC) </th>
</tr>

<tr>
<td>
<details>
<summary> Oral Session 1 | Learning theory / General ML  </summary>
<ul>
<li> Denoising and change point localisation in piecewise-constant high-dimensional regression coefficients 
</li>
<li> Noise Regularizes Over-parameterized Rank One Matrix Recovery, Provably
</li>
<li> Survival regression with proper scoring rules and monotonic neural networks
</li>
<li> Multivariate Quantile Function Forecaster
</li>
</ul>
</details>
</td>
<td>
08:30 - 09:30
</td>
</tr>

<tr>
<td>
<details>
<summary> Oral Session 2 | Bayesian methods / Sampling methods  </summary>
<ul>
<li>Differentiable Bayesian inference of SDE parameters using a pathwise series expansion of Brownian motion  
</li>
<li>Nonparametric Relational Models with Superrectangulation  
</li>
<li>Robust Bayesian Inference for Simulator-based Models via the MMD Posterior Bootstrap
</li>
<li>Unifying Importance Based Regularisation Methods for Continual Learning
</li>
</ul>
</details>
</td>
<td>
09:30 - 10:30
</td>
</tr>

<tr>
<td>
<details>
<summary> Oral Session 3 | Causality / Trustworthy ML  </summary>
<ul>
<li>Almost optimal universal lower bound for learning causal DAGs with atomic interventions
</li>
<li>Variance Minimization in the Wasserstein Space for Invariant Causal Prediction
</li>
<li>On the Assumptions of Synthetic Control Methods
</li>
<li>Differentially Private Densest Subgraph
</li>
</ul>
</details>
</td>
<td>
13:00 - 14:00
</td>
</tr>

<tr>
<td>
<details>
<summary> Oral Session 4 | Bandits / Reinforcement learning </summary>
<ul>
<li>Optimal Rates of (Locally) Differentially Private Heavy-tailed Multi-Armed Bandits
</li>
<li>Nonstochastic Bandits and Experts with Arm-Dependent Delays
</li>
<li>Towards Agnostic Feature-based Dynamic Pricing: Linear Policies vs Linear Valuation with Unknown Noise
</li>
<li>Towards an Understanding of Default Policies in Multitask Policy Optimization
</li>
</ul>
</details>
</td>
<td>
14:00 - 15:00
</td>
</tr>
</table>

## Day 2: Tue, March 29 

<table>
<tr>   
<th> Session Title </th>
<th> Time (UTC) </th>
</tr>

<tr>
<td>
<details>
<summary> Oral Session 5 |  Kernels / Optimization / Deep learning </summary>
<ul>
<li>Kernel Robust Smoothing
</li>
<li>A Single-Timescale Method for Stochastic Bilevel Optimization
</li>
<li>Lifted Primal-Dual Method for Bilinearly Coupled Smooth Minimax Optimization
</li>
<li>Generative Models as Distributions of Functions
</li>
</ul>
</details>
</td>

<td>
09:30 - 10:30
</td>
</tr>

<tr>
<td>
<details>
<summary> Oral Session 6 | Learning theory / Sampling methods </summary>
<ul>
<li>Amortized Rejection Sampling in Universal Probabilistic Programming
</li>
<li>Adaptive Importance Sampling meets Mirror Descent : a Bias-variance tradeoff
</li>
<li>"Loss as the Inconsistency of a Probabilistic Dependency Graph: Choose your Model, not your Loss Function"
</li>
<li>On the Consistency of Max-Margin Losses
</li>
</ul>
</details>
</td>
<td>
10:30 - 11:30 
</td>
</tr>


<tr>
<td>
<details>
<summary> Oral Session 7 | Bayesian methods / Deep learning </summary>
<ul>
<li>"Many processors, little time: MCMC for partitions via optimal transport couplings"
</li>
<li>Rapid Convergence of Informed Importance Tempering
</li>
<li>Projection Predictive Inference for Generalized Linear and Additive Multilevel Models
</li>
<li>Density Ratio Estimation via Infinitesimal Classification
</li>
</ul>
</details>
</td>
<td>
15:00 - 16:00
</td>
</tr>

</table>

## Day 3: Wed, March 30 

<table>

<tr>
<th>
Session Title
</th>
<th>
Time (UTC) 
</th> 
</tr>

<tr>
<td>
<details>
<summary>  Oral Session 8 | Learning theory / Sampling methods  </summary>
<ul>
<li>Sampling from Arbitrary Functions via PSD Models
</li>
<li>Orbital MCMC
</li>
<li>Hardness of Learning a Single Neuron with Adversarial Label Noise
</li>
<li>Data-splitting improves statistical performance in  overparameterized regimes
</li>
</ul>
</details>
</td>
<td>
07:00 - 08:00
</td>
</tr>


<tr>
<td>
<details>
<summary>Oral Session 9 | Reinforcement learning / Deep learning </summary> 
<ul>
<li>Beta Shapley: a Unified and Noise-reduced Data Valuation Framework for Machine Learning
</li>
<li>"Faster Rates, Adaptive Algorithms, and Finite-Time Bounds for Gradient Temporal-Difference Learning"
</li>
<li>A general class of surrogate functions for stable and efficient reinforcement learning
</li>
<li>A Complete Characterisation of ReLU-Invariant Distributions
</li>
</ul>
</details>
</td>
<td>
08:00 - 09:00 
</td>
</tr>


<tr>
<td>
<details>
<summary>Oral Session 10 | Gaussian processes / Optimization / Online ML </summary> 
<ul>
<li>Minimax Optimization: The Case of Convex-Submodular
</li>
<li>Doubly Mixed-Effects Gaussian Process Regression
</li>
<li>Fast and Scalable Spike and Slab Variable Selection in High-Dimensional Gaussian Processes
</li>
<li>Debiasing Samples from Online Learning Using Bootstrap
</li>
</ul>
</details>
</td>

<td>
13:00 - 14:00
</td>
</tr>


<tr>
<td>
<details>
<summary>Oral Session 11 | Bayesian methods / Sampling methods</summary> 

<ul>
<li>Entropy Regularized Optimal Transport Independence Criterion
</li>
<li>Two-Sample Test with Kernel Projected Wasserstein Distance
</li>
<li>Estimating Functionals of the Out-of-Sample Error Distribution in High-Dimensional Ridge Regression
</li>
<li>Heavy-tailed Streaming Statistical Estimation       
</li>
</ul>
</details>
</td>

<td>
14:00 - 15:00
</td>
</tr>
</table>

